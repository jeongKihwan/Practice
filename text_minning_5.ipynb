{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic modeling\n",
    "\n",
    "# 문서들을 주제별로 묶는 알고리즘..\n",
    "# 맥락과 관련 단어들을 이용하여 주제를 찾아내는 알고리즘.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp38-cp38-win_amd64.whl (24.2 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\tj\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\tj\\anaconda3\\lib\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\tj\\anaconda3\\lib\\site-packages (from gensim) (1.5.0)\n",
      "Collecting Cython==0.29.14\n",
      "  Downloading Cython-0.29.14-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\tj\\anaconda3\\lib\\site-packages (from gensim) (1.18.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-4.0.1.tar.gz (117 kB)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Created wheel for smart-open: filename=smart_open-4.0.1-py3-none-any.whl size=108253 sha256=7d213b3c82aa3df15181207c63015ecb7ea881009b323a080b413691249a7e38\n",
      "  Stored in directory: c:\\users\\tj\\appdata\\local\\pip\\cache\\wheels\\8c\\f9\\f4\\4ddd9ddee3488f48be20e9bf3108961f03ae23da29b7ed26d1\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.21\n",
      "    Uninstalling Cython-0.29.21:\n",
      "      Successfully uninstalled Cython-0.29.21\n",
      "Successfully installed Cython-0.29.14 gensim-3.8.3 smart-open-4.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('[\\w]+')   # 단어 기준으로 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')  # 불용어사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()   # 어근 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that brocolli is good for your health.\"\n",
    "doc_f = \"Big data is a term used to refer to data sets that are too large or complex for traditional data-processing application software to adequately deal with.\"\n",
    "doc_g = \"Data with many cases offer greater statistical power, while data with higher complexity may lead to a higher false discovery rate\"\n",
    "doc_h = \"Big data was originally associated with three key concepts: volume, variety, and velocity.\"\n",
    "doc_i = \"A 2016 definition states that 'Big data represents the information assets characterized by such a high volume, velocity and variety to require specific technology and analytical methods for its transformation into value'.\"\n",
    "doc_j = \"Data must be processed with advanced tools to reveal meaningful information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e, doc_f, doc_g, doc_h, doc_i, doc_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in doc_set:    \n",
    "    raw = doc.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if i not in stop_words]\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    texts.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['brocolli', 'good', 'eat', 'brother', 'like', 'eat', 'good', 'brocolli', 'mother'], ['mother', 'spend', 'lot', 'time', 'drive', 'brother', 'around', 'basebal', 'practic'], ['health', 'expert', 'suggest', 'drive', 'may', 'caus', 'increas', 'tension', 'blood', 'pressur'], ['often', 'feel', 'pressur', 'perform', 'well', 'school', 'mother', 'never', 'seem', 'drive', 'brother', 'better'], ['health', 'profession', 'say', 'brocolli', 'good', 'health'], ['big', 'data', 'term', 'use', 'refer', 'data', 'set', 'larg', 'complex', 'tradit', 'data', 'process', 'applic', 'softwar', 'adequ', 'deal'], ['data', 'mani', 'case', 'offer', 'greater', 'statist', 'power', 'data', 'higher', 'complex', 'may', 'lead', 'higher', 'fals', 'discoveri', 'rate'], ['big', 'data', 'origin', 'associ', 'three', 'key', 'concept', 'volum', 'varieti', 'veloc'], ['2016', 'definit', 'state', 'big', 'data', 'repres', 'inform', 'asset', 'character', 'high', 'volum', 'veloc', 'varieti', 'requir', 'specif', 'technolog', 'analyt', 'method', 'transform', 'valu'], ['data', 'must', 'process', 'advanc', 'tool', 'reveal', 'meaning', 'inform']]\n"
     ]
    }
   ],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(85 unique tokens: ['brocolli', 'brother', 'eat', 'good', 'like']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'brocolli')\n",
      "(1, 'brother')\n",
      "(2, 'eat')\n",
      "(3, 'good')\n",
      "(4, 'like')\n",
      "(5, 'mother')\n",
      "(6, 'around')\n",
      "(7, 'basebal')\n",
      "(8, 'drive')\n",
      "(9, 'lot')\n",
      "(10, 'practic')\n",
      "(11, 'spend')\n",
      "(12, 'time')\n",
      "(13, 'blood')\n",
      "(14, 'caus')\n",
      "(15, 'expert')\n",
      "(16, 'health')\n",
      "(17, 'increas')\n",
      "(18, 'may')\n",
      "(19, 'pressur')\n",
      "(20, 'suggest')\n",
      "(21, 'tension')\n",
      "(22, 'better')\n",
      "(23, 'feel')\n",
      "(24, 'never')\n",
      "(25, 'often')\n",
      "(26, 'perform')\n",
      "(27, 'school')\n",
      "(28, 'seem')\n",
      "(29, 'well')\n",
      "(30, 'profession')\n",
      "(31, 'say')\n",
      "(32, 'adequ')\n",
      "(33, 'applic')\n",
      "(34, 'big')\n",
      "(35, 'complex')\n",
      "(36, 'data')\n",
      "(37, 'deal')\n",
      "(38, 'larg')\n",
      "(39, 'process')\n",
      "(40, 'refer')\n",
      "(41, 'set')\n",
      "(42, 'softwar')\n",
      "(43, 'term')\n",
      "(44, 'tradit')\n",
      "(45, 'use')\n",
      "(46, 'case')\n",
      "(47, 'discoveri')\n",
      "(48, 'fals')\n",
      "(49, 'greater')\n",
      "(50, 'higher')\n",
      "(51, 'lead')\n",
      "(52, 'mani')\n",
      "(53, 'offer')\n",
      "(54, 'power')\n",
      "(55, 'rate')\n",
      "(56, 'statist')\n",
      "(57, 'associ')\n",
      "(58, 'concept')\n",
      "(59, 'key')\n",
      "(60, 'origin')\n",
      "(61, 'three')\n",
      "(62, 'varieti')\n",
      "(63, 'veloc')\n",
      "(64, 'volum')\n",
      "(65, '2016')\n",
      "(66, 'analyt')\n",
      "(67, 'asset')\n",
      "(68, 'character')\n",
      "(69, 'definit')\n",
      "(70, 'high')\n",
      "(71, 'inform')\n",
      "(72, 'method')\n",
      "(73, 'repres')\n",
      "(74, 'requir')\n",
      "(75, 'specif')\n",
      "(76, 'state')\n",
      "(77, 'technolog')\n",
      "(78, 'transform')\n",
      "(79, 'valu')\n",
      "(80, 'advanc')\n",
      "(81, 'meaning')\n",
      "(82, 'must')\n",
      "(83, 'reveal')\n",
      "(84, 'tool')\n"
     ]
    }
   ],
   "source": [
    "for i in dictionary.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 2), (1, 1), (2, 2), (3, 2), (4, 1), (5, 1)],\n",
       " [(1, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(8, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1)],\n",
       " [(1, 1),\n",
       "  (5, 1),\n",
       "  (8, 1),\n",
       "  (19, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (29, 1)],\n",
       " [(0, 1), (3, 1), (16, 2), (30, 1), (31, 1)],\n",
       " [(32, 1),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 3),\n",
       "  (37, 1),\n",
       "  (38, 1),\n",
       "  (39, 1),\n",
       "  (40, 1),\n",
       "  (41, 1),\n",
       "  (42, 1),\n",
       "  (43, 1),\n",
       "  (44, 1),\n",
       "  (45, 1)],\n",
       " [(18, 1),\n",
       "  (35, 1),\n",
       "  (36, 2),\n",
       "  (46, 1),\n",
       "  (47, 1),\n",
       "  (48, 1),\n",
       "  (49, 1),\n",
       "  (50, 2),\n",
       "  (51, 1),\n",
       "  (52, 1),\n",
       "  (53, 1),\n",
       "  (54, 1),\n",
       "  (55, 1),\n",
       "  (56, 1)],\n",
       " [(34, 1),\n",
       "  (36, 1),\n",
       "  (57, 1),\n",
       "  (58, 1),\n",
       "  (59, 1),\n",
       "  (60, 1),\n",
       "  (61, 1),\n",
       "  (62, 1),\n",
       "  (63, 1),\n",
       "  (64, 1)],\n",
       " [(34, 1),\n",
       "  (36, 1),\n",
       "  (62, 1),\n",
       "  (63, 1),\n",
       "  (64, 1),\n",
       "  (65, 1),\n",
       "  (66, 1),\n",
       "  (67, 1),\n",
       "  (68, 1),\n",
       "  (69, 1),\n",
       "  (70, 1),\n",
       "  (71, 1),\n",
       "  (72, 1),\n",
       "  (73, 1),\n",
       "  (74, 1),\n",
       "  (75, 1),\n",
       "  (76, 1),\n",
       "  (77, 1),\n",
       "  (78, 1),\n",
       "  (79, 1)],\n",
       " [(36, 1), (39, 1), (71, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1)]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic modeling : LDA기법을 활용.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=3, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.076*\"data\" + 0.037*\"big\" + 0.031*\"process\"'),\n",
       " (1, '0.035*\"drive\" + 0.033*\"health\" + 0.032*\"data\"'),\n",
       " (2, '0.056*\"brocolli\" + 0.056*\"good\" + 0.052*\"eat\"')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x214564fe8e0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.get_document_topics(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.95833457), (1, 0.02016741), (2, 0.021498024)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.get_document_topics(corpus)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 토픽 개수 지정하는 통계적 기법\n",
    "# 1. perplexity (혼잡도)\n",
    "#  - 문헌 내 주제 출현확률과 주제 내 용어출현 확률\n",
    "#  - 토픽수를 늘릴 수록 감소\n",
    "# 2. coherence (응집도)\n",
    "#  -  상위 단어 간의 유사도를 계산해서 유사한 단어끼리 모였는지 분석.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
